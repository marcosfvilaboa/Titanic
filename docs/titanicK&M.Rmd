---
title: "Tipologia i cicle de dades. Pràctica 2"
author: "Marcos F. Vilaboa & Joaquim Salomon"
date: "22 de mayo de 2019"
output: 
  pdf_document: 
    toc: true
    toc_depth: 3
    number_sections: true
    latex_engine: xelatex
  word_document: 
    toc: true
    toc_depth: 3
    number_sections: true
  html_document: 
    toc: true
    toc_depth: 3
    number_sections: true
lang: ca
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

___

# Introducció
En aquesta pràctica s’elabora un cas pràctic orientat a aprendre a identificar les dades rellevants per un projecte analític i usar les eines d’integració, neteja, validació i anàlisi de les mateixes.

## Competències
En aquesta pràctica es desenvolupen les següents competències del Màster de Data Science:
- Capacitat d'analitzar un problema en el nivell d'abstracció adequat a cada situació i aplicar les habilitats i coneixements adquirits per abordar-lo i resoldre'l.
- Capacitat per aplicar les tècniques específiques de tractament de dades (integració, transformació, neteja i validació) per al seu posterior anàlisi.

## Objectius
Els objectius concrets d’aquesta pràctica són:

- Aprendre a aplicar els coneixements adquirits i la seva capacitat de resolució de problemes en entorns nous o poc coneguts dintre de contextos més amplis o multidisciplinaris.

- Saber identificar les dades rellevants i els tractaments necessaris (integració, neteja i validació) per dur a terme un projecte analític.

- Aprendre a analitzar les dades adequadament per abordar la informació continguda en les dades.

- Identificar la millor representació dels resultats per tal d’aportar conclusions sobre el problema plantejat en el procés analític.

- Actuar amb els principis ètics i legals relacionats amb la manipulació de dades en funció de l'àmbit d'aplicació.

- Desenvolupar les habilitats d'aprenentatge que els permetin continuar estudiant d'una manera que haurà de ser en gran manera autodirigida o autònoma.

- Desenvolupar la capacitat de cerca, gestió i ús d'informació i recursos en l'àmbit de la ciència de dades.

# Resolució
## Descripció del *dataset*
El conjunt de dades utilitzat en el present anàlisi s'ha extret de la web [kaggle.com](https://www.kaggle.com "Pàgina principal de Kaggle"). Concretament s'ha utilitzat el *set* d'entrenament (train.csv) que forma part del total de dades de Titanic: Machine Learning from Disaster (<https://www.kaggle.com/c/titanic/data>).

### Càrrega inicial de dades
Per tal de descriure el conjunt, realitzarem una càrrega inicial de les dades amb R:
```{r}
titanic.original <- read.csv("../data/titanic_train.csv", header=TRUE)
str(titanic.original)
```

Inicialment, el *dataset* es composa de 12 variables (columnes) amb un total de 891 observacions (registreS). 

### Descripció de les variables
La definició de cada camp és la següent:

- _**PassengerId**_ (*int*): identificador únic del passatger (i de cada registre).

- _**Survived**_ (*int*): si el passatger va sobreviure o no. "0" = No i "1" = Si
  
- _**Pclass**_ (*int*): classe del bitllet d'embarcament. "1" = primera classe, "2" = segona i "3" = tercera.
  
- _**Name**_ (*int*): nom del passatger. Inclou el títol com "Mr.", "Mrs.", "Dr.", ...
  
- _**Sex**_ (*Factor*): gènere del passatger. "female" = dona i "male" = home. 

- _**Age**_ (*num*): edat.

- _**SibSp**_ (*Factor*): nombre de germans i cònjuges a bord.

- _**Parch**_ (*int*): nombre de pares i fills a bord.

- _**Ticket**_ (*Factor*): número de tiquet.

- _**Fare**_ (*num*): tarifa del passatger.

- _**Cabin**_ (*Factor*): número de camarot. Consta d'una lletra que significa la coberta i el número de camarot: "A10", "C85",...

- _**Embarked**_ (*Factor*): port a on el passatger va embarcar: "C" = Cherbourg, "S" = Southampton i "Q" = Queenstown

### Importància i objectius
El Titanic es va enfonsar, durant el seu viatge inaugural el 15 d'abril de 1912, xocant amb un iceberg. Van morir 1502 passatgers i tripulants d'un total de 2224. 

La raó principal d'aquest número tan important de víctimes de la tragèdia va ser la quantitat escassa de bots salvavides envers el nombre de vides a bord. Es diu que, per preferència, els nens, les dones i la classe alta tenien més possibilitats de sobreviure.

L'objectiu principal d'aquest estudi és el de conèixer si aquesta afirmació és certa. Es pretén doncs, respondre a la pregunta de quin grup de persones va tenir mes possibilitats de sobreviure i quin tipus de característiques té.

## Pre-processament
### Integració i selecció de les dades

La integració de les dades consisteix a combinar les dades de diferents fonts de dades. En aquest cas, com que ens basem en un *dataset* concret, no serà necessari integrar més fonts. 

En canvi, 
```{r}
titanic <- titanic.original[,-which(names(titanic.original) %in% c("Embarked","Ticket","PassengerId"))]
```


### Neteja de les dades

#### Zeros y elements buits

En primer lloc, cal comprovar que les dades no continguin elements buits o zeros. Per a fer-ho, primerament ens fixem en la primera mostra de les dades que s'ha pogut veure unes línies més amunt on es pot veure dades que equivalen a valors buits "" i també valors nul·ls representats com NA. 
Aleshores, anem a veure quins camps contenen aquestes dades nul·les o buides.
Per a veure les dades buides executem la següent funció per veure el nombre d'atributs que contenen algun camp buit.
```{r}
colSums(titanic=="")
```

I en aquest pas es farà el mateix per a dades nul·les.

```{r}
colSums(is.na(titanic))
```

Així doncs, els atributs _Cabin_ i _Age_ contenen dades a tractar.

Per a l'atribut _Cabin_ veiem que una gran part dels valors de l'atribuit són buits o nul·ls, aleshores s'haurà de prescindir d'aquest atribuit ja que no pot aportar cap informació rellevant.

Eliminem l'atribut.

```{r}
titanic["Cabin"] <- NULL
```


Per últim, els valors nul·ls de l'atribut _Age_ els substituim per la mitjana dels valors no nul·ls:

```{r}
titanic$Age[is.na(titanic$Age)] <- mean(titanic$Age,na.rm=T)
```


#### Valors extrems

A continuació creem una funció per a trobar els valors extrems dins dels atributs numèrics i una altra per esobrrar-los en cas que sigui necessari. En aquest cas concret en tenim quatre: _Age_, _SibSp_, _Parch_ i _Fare_
```{r}
seeOutlierValues <- function(dataset,arrayToCheck) {
  mean <- mean(arrayToCheck)
  standardDev <- sd(mean(arrayToCheck))
  min_value <- mean(arrayToCheck)-3*sd(arrayToCheck)
  max_value <- mean(arrayToCheck)+3*sd(arrayToCheck)
  newDatasetWOutliers <- dataset[(arrayToCheck<=min_value | arrayToCheck>=max_value),]
  outliers_count <- nrow(dataset)-nrow(newDatasetWOutliers)
  return (newDatasetWOutliers)
}

removeOutlierValues <- function(dataset,arrayToCheck) {
  mean <- mean(arrayToCheck)
  standardDev <- sd(mean(arrayToCheck))
  min_value <- mean(arrayToCheck)-3*sd(arrayToCheck)
  max_value <- mean(arrayToCheck)+3*sd(arrayToCheck)
  newDatasetWoOutliers <- dataset[(arrayToCheck>=min_value & arrayToCheck<=max_value),]
  outliers_count <- nrow(dataset)-nrow(newDatasetWoOutliers)
  cat("From", deparse(substitute(arrayToCheck)), outliers_count, "skipped tuples", "\n\n") 
  return (newDatasetWoOutliers)
}
```

Primerament, es miren els outliers per a cada variable i després de fer una valoració es decideix borrar-los o mantenir-los.

En el case de _Fare_ com es pot veure a continuació els outliers, considerant outliers els valors que estan a més de tres desviacions estàndard de la mitja, no són discordants. Per tant, no es veu la necessitat d'esborrar-los.

```{r}
seeOutlierValues(titanic, titanic$Fare)
```

Per les variables _SibSP_ i _Parch_ es decideix unir les variables, ja que tots fan referència a familia abord del vaixell. Aleshores, amb la variable conjunta es miren els outliers i es considera que tampoc són discordants ja que les famílies de mida més petita són les que tenen algun component que sobreviu.
```{r}
titanic$Family_size <- titanic$SibSp + titanic$Parch
seeOutlierValues(titanic, titanic$Family_size)
```
Descartem els atributs origen:
```{r}
titanic["SibSp"] <- NULL
titanic["Parch"] <- NULL
```

I per últim, a la variable _Age_, si que es decideixen suprimir els outliers ja que precissament la persona més gran és la que sobreviu i això pot comportar a errors d'anàlisis.
```{r}
seeOutlierValues(titanic, titanic$Age)
titanic <- removeOutlierValues(titanic, titanic$Age)
```

#### Transformació de les variables
En aquest cas, l'atribut _Name_ pot tenir algun valor, ja que en aquesta s'hi pot trobar el títol de la persona. Així, es decideix extreure aquest títol del nom 
```{r}
titanic$Title <- as.factor(gsub('(.*, )|(\\..*)', '', titanic$Name))
```
i conservar només el nou atribut _Title_ derivat de _Name_.
```{r}
titanic["Name"] <- NULL #La variable Name ja no té cap valor
```
S'unifiquen valors per reduir la grandària del grup
```{r}
library(dplyr)
levels(titanic$Title)
titles_lookup <- data.frame(Title = c("Capt", "Col", "Don", "Dr", "Jonkheer", "Major", "Rev", "Sir",
                                      "Mr", "Master", 
                                      "Lady", "Mlle", "Mme", "Ms", "the Countess",
                                      "Mrs", "Miss"), 
                            New.Title = c(rep("Noble male", 8),
                                          "Mr", "Master",
                                          rep("Noble female", 5),
                                          "Mrs", "Miss"),
                            stringsAsFactors = FALSE)
```
S'inclouen en el dataset
```{r}
titanic <- titanic %>%
  left_join(titles_lookup, by = "Title")

titanic <- titanic %>%
  mutate(Title = New.Title) %>%
  select(-New.Title)
```
i es visualitzen possibles errors de sexe en el títol
```{r}
titanic %>%
  filter((Sex == "female" & (Title == "Noble male" | Title == "Mr" | Title == "Master") |
           (Sex == "male" & (Title == "Noble female" | Title == "Mrs" | Title == "Miss"))))
```
Com es pot veure, ha detectat una dona com a _Noble male_ i la corregim:
```{r}
titanic <- titanic %>%
  mutate(Title=replace(Title, (Sex == "female" & (Title == "Noble male")), "Noble female"))
```

Per finalitzar, caldrà transformar les variables categòriques en factors per poder tractar-les més fàcilment en l'anàlisis
```{r}
titanic$Survived <- as.factor(titanic$Survived)
titanic$Pclass <- as.factor(titanic$Pclass)
titanic$Title <- as.factor(titanic$Title)
```


### Exportació de les dades preprocessades
Un cop transformat el dataset s'exporta en un ".csv"

```{r}
write.csv(titanic, "../data/titanic_train_transformed.csv")
```

## Anàlisi de les dades

### Selecció dels grups de dades
Primer de tot, i com que _Survived_ és la variable de classe i, com a tal de tipus factor, però per als següents càlculs la farem servir com a referència numèrica, la passarem a tipus _integer_.
```{r}
#Es resta 1 al convertir-lo a integer ja que els valors passen a ser 1 i 2 al transformar-lo
titanic$Survived <- as.integer(titanic$Survived)-1
```
En aquesta secció es preparen els grups dividint-los segons els valors dels diferents atributs i amb la funció _seeGroupStatics_ (creada a continuació) es podrà fer una primer anàlisis.
```{r}
seeGroupStatics <- function(resultArray, categoricalArray){
  aggregate(resultArray, list(categoricalArray), FUN = function(x) c(mean = mean(x), count = length(x) ))
}
```
Una de les agrupacions és a partir de la variable _Pclass_ a on podem categoritzar els passatgers segons si van embarcar amb 1a, 2a o 3a classe.
```{r}
levels(titanic$Pclass)
seeGroupStatics(titanic$Survived, titanic$Pclass)
t_pclass_1 <- titanic %>% filter(Pclass == "1")
t_pclass_2 <- titanic %>% filter(Pclass == "2")
t_pclass_3 <- titanic %>% filter(Pclass == "3")
```
La següent es _Title_ 
```{r}
levels(titanic$Title)
seeGroupStatics(titanic$Survived, titanic$Title)
t_title_Master <- titanic %>% filter(Title == "Master")
t_title_Miss <- titanic %>% filter(Title == "Miss")
t_title_Mr <- titanic %>% filter(Title == "Mr")
t_title_Mrs <- titanic %>% filter(Title == "Mrs")
t_title_Noble_female <- titanic %>% filter(Title == "Noble female")
t_title_Noble_male <- titanic %>% filter(Title == "Noble male")
```
Per _Sex_:
```{r}
levels(titanic$Sex)
seeGroupStatics(titanic$Survived, titanic$Sex)
t_sex_male <- titanic %>% filter(Sex == "male")
t_sex_female <- titanic %>% filter(Sex == "female")
```
A _Age_ els agrupem en les categoríes _Youth_, _Young Adult_, _Adult_ i _Senior_, segons si tenen de 0 a 15 anys, de 16 a 35, de 36 a 50 i de 51 a 70 respectivament.
```{r}
max(titanic$Age)
titanic$AgeCategorical<-cut(titanic$Age, seq(0,70,5))
seeGroupStatics(titanic$Survived, titanic$AgeCategorical)
titanic$AgeCategorical <- cut(titanic$Age, breaks=c(0, 15, 35, 50, 70), labels=c("Youth","Young Adult","Adult","Senior"))
seeGroupStatics(titanic$Survived, titanic$AgeCategorical)
t_age_youth <- titanic %>% filter(AgeCategorical == "Youth")
t_age_youngAdult <- titanic %>% filter(AgeCategorical == "Young Adult")
t_age_adult <- titanic %>% filter(AgeCategorical == "Adult")
t_age_senior <- titanic %>% filter(AgeCategorical == "Senior")
```


### Comprovació de la normalitat i homogeneïtat de la variància
#### Normalitat
Comprovar si les dades segueixen una distribució normal es pot realitzar de diverses maneres. Es pot comprovar gràficament si segueix una corba en forma de campana. Es a dir la probabilitat d'obtenir una observació serà més alta al centre de la corba mentres que disminueix a mesura que ens allunyem del mig. 
Farem servir la llibreria _ggplot2_ per visualitzar l'histograma de les variables numèriques.
Per exemple, per al cas de la variable _Age_:
```{r}
library(ggplot2)
### See normality of 'Age' by plot
ggplot(titanic, aes(x=Age)) + 
  geom_histogram(aes(y=..density..), binwidth = 6, colour="black", fill="lightblue")
```
A simple vista, sembla seguir una distribució normal.

Una altra manera de descriure la seva normalitat és pels paràmetres mitjana i desviació estàndard. Molts algoritmes de prova de la normalitat supòsen que les dades s'adapten a la distribució de probabilitat normal mitjançant la desviació estàndard i la mitjana. Aquestes proves, denominades paramètriques, les podem trobar als test _Kolmogorov-Smirnov_ o _Shapiro-Wilk_. Assumeixen la hipòtesi nul·la de que les dades es distribueixen normalment. Si el _p-valor_ es més baix al nivell de significància (assumirem $\alpha=0.05$) es rebutja la hipòtesi nul·la i s'assumeix que la població no segueix una distribució normal.

En el cas de _Age_:
```{r}
shapiro.test(titanic$Age)
```
Resulta en ditribució no normal. El _p-valor_ és 5.094e-14, molt inferior al nivell de significància.

Provarem amb la variable _Fare_. Primer gràficament:
```{r}
ggplot(titanic, aes(x=Fare)) + 
  geom_histogram(aes(y=..density..), binwidth = 40, colour="black", fill="lightblue")
```
Es tracta d'una distribució no normal de cua a la dreta. Ho comprovem amb _Shapiro-Wilk_:
```{r}
shapiro.test(titanic$Fare)
```
Per últim, revisarem l'atribut _Family Size_:
```{r}
ggplot(titanic, aes(x=Family_size)) + 
  geom_histogram(aes(y=..density..), binwidth = 0.8, colour="black", fill="lightblue")
```
Tornem a tenir una distribució no normal de cua a la dreta. Revisem-ho amb el test:
```{r}
shapiro.test(titanic$Family_size)
```


#### Homogeneïtat
Bàsicament, la homogeneitat es tracta de la igualtat de variances entre els grups a comparar. Els algoritmes poden ser el test de _Levene_ si les dades segueixen una distribució normal o bé el test no paramètric de _Fligner-Killeen_ en cas de no normalitat en la mostra. Anàlogament al cas dels tests de normalitat, s'assumeix la hipòtesi nul·la amb un nivell de significància $\alpha=0.05$ i, si el _p-valor_ es superior a aquesta, indicarà que les variances entre els grups son iguales i, per tant, homogènies.

Degut als resultats de les proves de normalitat, s'utilitzarà el test _Fligner-Killeen_. 

Per _Age_:
```{r}
library(car)
fligner.test(as.integer(Survived) ~ Age, data = titanic)
```
Es comprova que el _p-valor_ és superior al nivell de significància i, per tant, acceptem la hipòtesi nul·la significant que ambdues mostres són homogènies. 

Per a _Fare_:
```{r}
fligner.test(as.integer(Survived) ~ Fare, data = titanic)
```
També son homogènies.

Per últim, _Family-size_:
```{r}
fligner.test(as.integer(Survived) ~ Family_size, data = titanic)
```
El _p-valor_ 0.0009094, menor al nivell de significància, rebutja la hipòtesi nul·la indicant variances estadísticament diferents (hetergoneïtat).

### Aplicació de proves estadístiques 
**TO-DO: En funció de les dades i de l’objectiu de l’estudi, aplicar proves de contrast d’hipòtesis, correlacions, regressions, etc. Aplicar almenys tres mètodes d’anàlisi diferents.**

## Representació dels resultats
TO-DO: Taules i gràfiques

## Resolució del problema
TO-DO: A partir dels resultats obtinguts, quines són les conclusions? Els resultats permeten respondre al problema?
